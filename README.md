# OpenClaw Voice

**Open-source browser-based voice interface for AI assistants.**

Talk to your AI like you talk to Alexa â€” but self-hosted, private, and connected to your own agent.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-green.svg)

ğŸŒ **Website:** [openclawvoice.com](https://openclawvoice.com)

## Features

| Feature | Description |
|---------|-------------|
| ğŸ¤ **Local STT** | Whisper runs locally via faster-whisper. Your voice never leaves your machine. |
| ğŸ”Š **Streaming TTS** | ElevenLabs with sentence-by-sentence streaming. Hear responses while they generate. |
| ğŸ¯ **Voice Activity Detection** | Silero VAD filters background noise. Works in noisy environments. |
| ğŸ§¹ **Smart Text Cleaning** | Strips markdown, hashtags, URLs before TTS. No more "hash hash". |
| ğŸ”Œ **Any AI Backend** | OpenAI, Claude, or full OpenClaw agent with memory and tools. |
| ğŸŒ **Browser-Based** | No app install. Works on desktop and mobile. |
| ğŸš— **Continuous Mode** | Hands-free conversation. Auto-listens after each response. |

## Quick Start

```bash
# Clone
git clone https://github.com/Purple-Horizons/openclaw-voice.git
cd openclaw-voice

# Install
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Optional: Install VAD support (better noise handling)
pip install torch torchaudio

# Configure (create .env from example)
cp .env.example .env
# Edit .env with your API keys

# Run
PYTHONPATH=. python -m src.server.main

# Open http://localhost:8765
```

## For OpenClaw Agents (Auto-Install)

One-liner for AI agents to self-install:

```bash
cd /tmp && \
git clone https://github.com/Purple-Horizons/openclaw-voice.git && \
cd openclaw-voice && \
python3 -m venv .venv && source .venv/bin/activate && \
pip install -r requirements.txt torch torchaudio && \
PYTHONPATH=. ELEVENLABS_API_KEY="$ELEVENLABS_API_KEY" OPENAI_API_KEY="$OPENAI_API_KEY" \
  nohup python -m src.server.main > /tmp/voice-server.log 2>&1 &
```

## Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `ELEVENLABS_API_KEY` | Yes* | â€” | ElevenLabs API key for TTS |
| `OPENAI_API_KEY` | Yes* | â€” | OpenAI API key (if not using gateway) |
| `OPENCLAW_GATEWAY_URL` | No | â€” | OpenClaw gateway URL for full agent |
| `OPENCLAW_GATEWAY_TOKEN` | No | â€” | Gateway auth token |
| `OPENCLAW_PORT` | No | `8765` | Server port |
| `OPENCLAW_STT_MODEL` | No | `base` | Whisper model size |
| `OPENCLAW_STT_DEVICE` | No | `auto` | Device: `auto`, `cpu`, `cuda`, `mps` |
| `OPENCLAW_REQUIRE_AUTH` | No | `false` | Require API keys for clients |

*One of `OPENAI_API_KEY` or `OPENCLAW_GATEWAY_URL` required.

### Whisper Model Sizes

| Model | Speed | Quality | VRAM | Best For |
|-------|-------|---------|------|----------|
| `tiny` | Fastest | Fair | ~400MB | Quick testing |
| `base` | Fast | Good | ~1GB | **Default. Good balance.** |
| `small` | Medium | Better | ~2GB | Clearer transcription |
| `medium` | Slower | Great | ~5GB | Accuracy priority |
| `large-v3-turbo` | Slow | Best | ~6GB | Maximum accuracy |

### TTS Options

| Backend | Type | Quality | Latency | Notes |
|---------|------|---------|---------|-------|
| **ElevenLabs** | Cloud | Excellent | ~500ms | Default. Streaming supported. |
| **Telnyx** | Cloud | Very Good | ~300ms | Cost-effective. Streaming supported. |
| Chatterbox | Local | Very Good | ~1s | MIT license, voice cloning |
| XTTS-v2 | Local | Excellent | ~1s | Voice cloning supported |
| Mock | Local | None | 0ms | For testing (silence) |

ElevenLabs uses `eleven_turbo_v2_5` for fastest response.
Telnyx uses OpenAI-compatible TTS API via `api.telnyx.com/v2/ai`.

### STT Options

| Backend | Type | Quality | Latency | Notes |
|---------|------|---------|---------|-------|
| **Telnyx** | Cloud | Excellent | ~200ms | No GPU required. OpenAI-compatible. |
| faster-whisper | Local | Excellent | ~500ms | GPU accelerated. Default if no cloud. |
| openai-whisper | Local | Good | ~1s | CPU fallback |
| Mock | Local | None | 0ms | For testing |

## OpenClaw Gateway Integration

Connect to your full OpenClaw agent (same memory, tools, and persona as text chat):

```bash
# .env
OPENCLAW_GATEWAY_URL=http://localhost:18789
OPENCLAW_GATEWAY_TOKEN=your-token
ELEVENLABS_API_KEY=your-key
```

Add to your `openclaw.json`:

```json
{
  "gateway": {
    "http": {
      "endpoints": {
        "chatCompletions": { "enabled": true }
      }
    }
  },
  "agents": {
    "list": [
      {
        "id": "voice",
        "workspace": "/path/to/workspace",
        "model": "anthropic/claude-sonnet-4-5"
      }
    ]
  }
}
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   WebSocket   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚          Voice Server               â”‚
â”‚  (mic/spk)  â”‚               â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                              â”‚  â”‚ Whisper â”‚â†’â”‚ AI  â”‚â†’â”‚ElevenLabsâ”‚ â”‚
                              â”‚  â”‚  (STT)  â”‚  â”‚     â”‚  â”‚  (TTS)  â”‚ â”‚
                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                              â”‚       â†‘                     â”‚      â”‚
                              â”‚    [VAD]              [streaming]  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Streaming Flow:**
1. User speaks â†’ Whisper transcribes locally
2. AI responds (streamed) â†’ buffer sentences
3. First sentence complete â†’ TTS starts immediately
4. Audio streams to browser while AI continues
5. Result: ~50% faster perceived response

## Telnyx Integration

OpenClaw Voice supports Telnyx as an alternative provider for STT, TTS, and phone calling.

### Cloud STT/TTS

Set `TELNYX_API_KEY` to use Telnyx AI Inference API instead of running Whisper locally:

```bash
# .env
TELNYX_API_KEY=your-telnyx-api-key
```

Benefits:
- No GPU required for STT
- Lower latency for cold starts
- Cost-effective at scale

### Phone Calling (WebRTC)

Enable AI-to-phone calls via Telnyx WebRTC:

```bash
# .env
TELNYX_API_KEY=your-telnyx-api-key
TELNYX_SIP_USERNAME=your-sip-username
TELNYX_SIP_PASSWORD=your-sip-password
TELNYX_CALLER_ID=+15551234567
```

The `TelnyxWebRTCClient` enables:
- Outbound calls to any phone number
- Inbound call handling
- Bidirectional audio streaming
- DTMF tone support for IVR

See `src/server/telnyx_webrtc.py` for API details.

## HTTPS for Mobile

Mobile browsers require HTTPS for microphone access. Options:

**Tailscale Funnel (easiest):**
```bash
tailscale funnel 8765
# Access via https://your-machine.tailnet-name.ts.net
```

**nginx + Let's Encrypt:**
```nginx
server {
    listen 443 ssl;
    server_name voice.yourdomain.com;
    
    location / {
        proxy_pass http://127.0.0.1:8765;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

## API

### WebSocket Protocol

Connect to `ws://localhost:8765/ws`:

```javascript
// Start recording
{ "type": "start_listening" }

// Send audio (base64 PCM float32, 16kHz)
{ "type": "audio", "data": "base64..." }

// Stop recording
{ "type": "stop_listening" }

// Receive events:
{ "type": "transcript", "text": "...", "final": true }
{ "type": "response_chunk", "text": "..." }        // Streaming text
{ "type": "audio_chunk", "data": "...", "sample_rate": 24000 }  // Streaming audio
{ "type": "response_complete", "text": "..." }     // Full response
{ "type": "vad_status", "speech_detected": true }  // VAD feedback
```

## Roadmap

- [x] WebSocket voice gateway
- [x] Whisper STT (local)
- [x] ElevenLabs TTS
- [x] Streaming TTS (sentence-by-sentence)
- [x] Voice Activity Detection (Silero)
- [x] Text cleaning (markdown/hashtags/URLs)
- [x] Continuous conversation mode
- [x] OpenClaw gateway integration
- [x] Telnyx STT/TTS integration
- [x] Telnyx WebRTC phone calling
- [ ] WebRTC for browser lower latency
- [ ] Voice cloning UI
- [ ] Docker support

## License

MIT License â€” see [LICENSE](LICENSE).

## Credits

- [faster-whisper](https://github.com/guillaumekln/faster-whisper) â€” Local STT
- [ElevenLabs](https://elevenlabs.io) â€” Text-to-Speech
- [Silero VAD](https://github.com/snakers4/silero-vad) â€” Voice Activity Detection
- Built for [OpenClaw](https://openclaw.ai)

---

**Made with ğŸ¦ by [Purple Horizons](https://purplehorizons.io)**
